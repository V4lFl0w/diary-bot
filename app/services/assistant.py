# app/services/assistant.py
from __future__ import annotations

import os
import json
import re
from datetime import datetime, timezone, timedelta, time as dtime
from typing import Optional, Any

from zoneinfo import ZoneInfo
from sqlalchemy import select, desc
try:
    from openai import AsyncOpenAI
except ModuleNotFoundError:
    AsyncOpenAI = None  # type: ignore

from app.models.user import User
from app.models.journal import JournalEntry
from app.services.llm_usage import log_llm_usage
from app.services.media_id import trace_moe_identify
from app.services.media_search import tmdb_search_multi, build_media_context


MENU_NOISE = {
    "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üßæ –°–µ–≥–æ–¥–Ω—è", "üìì –ñ—É—Ä–Ω–∞–ª", "üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é",
    "üíé –ü—Ä–µ–º–∏—É–º", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", "üßò –ú–µ–¥–∏–∞",
}

ANTI_HALLUCINATION_PREFIX = (
    "–í–ê–ñ–ù–û:\n"
    "- –ï—Å–ª–∏ —Ç—ã –ù–ï –£–í–ï–†–ï–ù(–∞) ‚Äî –ø—Ä—è–º–æ —Å–∫–∞–∂–∏: '–Ω–µ —É–≤–µ—Ä–µ–Ω(–∞)'.\n"
    "- –ù–ï —É–≥–∞–¥—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–æ–≤/–º—É–ª—å—Ç—Ñ–∏–ª—å–º–æ–≤/–ª—é–¥–µ–π/–º–µ—Å—Ç.\n"
    "- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –≤–∏–¥–Ω–æ.\n"
    "- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –∑–∞–¥–∞–π 1 —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.\n\n"
)

MEDIA_NOT_FOUND_REPLY_RU = (
    "–ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ. –î–∞–π 1 –¥–µ—Ç–∞–ª—å, –∏ —è –ø–æ–ø—Ä–æ–±—É—é –µ—â—ë —Ä–∞–∑: "
    "–≥–æ–¥ / –∞–∫—Ç—ë—Ä / —Å—Ç—Ä–∞–Ω–∞ / —è–∑—ã–∫ / —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Å—Ü–µ–Ω–µ (1‚Äì2 —Ñ–∞–∫—Ç–∞)."
)






def _is_asking_for_title(text: str) -> bool:
    t = (text or "").strip().lower()
    pats = (
        "–∫–∞–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ", "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è", "–Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞", "–Ω–∞–∑–≤–∞–Ω–∏–µ —É —Ñ–∏–ª—å–º–∞",
        "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ñ–∏–ª—å–º", "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —ç—Ç–æ—Ç —Ñ–∏–ª—å–º", "—á—Ç–æ –∑–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ",
    )
    return any(x in t for x in pats)

def _is_affirmation(text: str) -> bool:
    t = (text or "").strip().lower()
    return bool(re.match(r"^(–¥–∞|–∞–≥–∞|—É–≥—É)\b", t)) or t.startswith("—ç—Ç–æ ") or t.startswith("–¥–∞,") or t.startswith("–¥–∞ ")

def _extract_search_query_from_text(s: str) -> str:
    s = s or ""
    m = re.search(r"(?im)^\s*SEARCH_QUERY:\s*(.*)\s*$", s)
    if m:
        return (m.group(1) or "").strip()
    return ""


def _normalize_tmdb_query(q: str, *, max_len: int = 140) -> str:
    """
    TMDb search query must be short and clean.
    - collapse whitespace/newlines
    - strip quotes/markdown-ish noise
    - hard truncate
    """
    q = (q or "").strip()
    if not q:
        return ""

    # remove "SEARCH_QUERY:" if user pasted it
    q = re.sub(r"(?im)^\s*SEARCH_QUERY:\s*", "", q).strip()

    # collapse whitespace/newlines
    q = re.sub(r"\s+", " ", q).strip()

    # avoid super-long paragraphs (TMDb can return 400)
    if len(q) > max_len:
        q = q[:max_len].rsplit(" ", 1)[0].strip()

    # remove leading generic junk
    q = re.sub(r"^(—á—Ç–æ –∑–∞|–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è)\s+", "", q, flags=re.I).strip()
    return q

# --- media session cache (in-memory, no DB migrations) ---
from time import time as _time_now

_MEDIA_TTL_SEC = 10 * 60
_MEDIA_SESSIONS: dict[str, dict] = {}

def _media_uid(user: Any) -> str:
    # prefer tg_id, fallback to db id
    if not user:
        return ""
    v = getattr(user, "tg_id", None) or getattr(user, "id", None)
    return str(v) if v is not None else ""

def _media_get(uid: str) -> Optional[dict]:
    if not uid:
        return None
    s = _MEDIA_SESSIONS.get(uid)
    if not s:
        return None
    if (_time_now() - float(s.get("ts", 0))) > _MEDIA_TTL_SEC:
        _MEDIA_SESSIONS.pop(uid, None)
        return None
    return s

def _media_set(uid: str, query: str, items: list[dict]) -> None:
    if not uid:
        return
    q = _normalize_tmdb_query(query)
    _MEDIA_SESSIONS[uid] = {"query": q, "items": items or [], "ts": _time_now()}

def _looks_like_choice(text: str) -> bool:
    t = (text or "").strip()
    return bool(re.fullmatch(r"\d{1,2}", t))

def _looks_like_year_or_hint(text: str) -> bool:
    t = (text or "").strip().lower()
    if re.search(r"\b(19\d{2}|20\d{2})\b", t):
        return True
    # –∫–æ—Ä–æ—Ç–∫–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è: –∞–∫—Ç—ë—Ä/—Å—Ç—Ä–∞–Ω–∞/—è–∑—ã–∫/–≥–æ–¥/—Å–µ—Ä–∏—è/—ç–ø–∏–∑–æ–¥
    hint_words = ("–≥–æ–¥", "–∞–∫—Ç", "–∞–∫—Ç–µ—Ä", "–∞–∫—Ç—ë—Ä", "—Å—Ç—Ä–∞–Ω–∞", "—è–∑—ã–∫", "—Å–µ—Ä–∏—è", "—ç–ø–∏–∑–æ–¥", "—Å–µ–∑–æ–Ω")
    return any(w in t for w in hint_words) or (len(t) <= 30 and " " in t)


def _extract_year(text: str) -> Optional[str]:
    m = re.search(r"\b(19\d{2}|20\d{2})\b", (text or ""))
    return m.group(1) if m else None


def _parse_media_hints(text: str) -> dict:
    t = (text or "").lower()

    year = None
    m = re.search(r"\b(19\d{2}|20\d{2})\b", t)
    if m:
        year = m.group(1)

    kind = None
    if "—Å–µ—Ä–∏–∞–ª" in t:
        kind = "tv"
    elif "—Ñ–∏–ª—å–º" in t or "–∫–∏–Ω–æ" in t:
        kind = "movie"

    cast = re.findall(r"\b[A-Z][a-z]+ [A-Z][a-z]+\b", text)

    keywords = re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9 ]", " ", text)
    keywords = " ".join(w for w in keywords.split() if len(w) > 3)[:80]

    return {"year": year, "kind": kind, "cast": cast[:2], "keywords": keywords.strip()}


def _dedupe_media(items: list[dict]) -> list[dict]:
    seen = set()
    out: list[dict] = []
    for it in items or []:
        key = (
            it.get("media_type"),
            it.get("id"),
            ((it.get("title") or "") + "|" + (it.get("name") or "")).lower(),
            it.get("year"),
        )
        if key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out


def _sort_media(items: list[dict]) -> list[dict]:
    def score(it: dict) -> float:
        try:
            return float(it.get("popularity") or 0) * 0.8 + float(it.get("vote_average") or 0) * 2.0
        except Exception:
            return 0.0

    return sorted(items or [], key=score, reverse=True)


async def _tmdb_best_effort(query: str, *, limit: int = 5) -> list[dict]:
    """
    Best-effort TMDb retrieval:
    - ru-RU first
    - fallback to en-US (TMDb —á–∞—Å—Ç–æ –±–æ–≥–∞—á–µ –Ω–∞ EN)
    - dedupe + soft year filter + sort by usefulness
    """
    q = _normalize_tmdb_query(query)
    if not q:
        return []

    year = _extract_year(q)

    items: list[dict] = []
    try:
        items_ru = await tmdb_search_multi(q, lang="ru-RU", limit=limit)
    except Exception:
        items_ru = []

    if items_ru and isinstance(items_ru[0], dict) and items_ru[0].get("_error"):
        items_ru = []

    items_en: list[dict] = []
    if not items_ru:
        try:
            items_en = await tmdb_search_multi(q, lang="en-US", limit=limit)
        except Exception:
            items_en = []

        if items_en and isinstance(items_en[0], dict) and items_en[0].get("_error"):
            items_en = []

    items = _dedupe_media((items_ru or []) + (items_en or []))

    if year:
        filtered = [it for it in items if str(it.get("year") or "") == year]
        if filtered:
            items = filtered

    return _sort_media(items)[:limit]


def _format_one_media(item: dict) -> str:
    # items come from tmdb_search_multi(): title/year/media_type/overview/vote_average
    title = (item.get("title") or item.get("name") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è").strip()
    year = (item.get("year") or "").strip()
    overview = (item.get("overview") or "").strip()
    rating = item.get("vote_average", None)
    kind = (item.get("media_type") or "").strip()
    kind_ru = "—Å–µ—Ä–∏–∞–ª" if kind == "tv" else "—Ñ–∏–ª—å–º" if kind == "movie" else kind or "–º–µ–¥–∏–∞"

    line = f"üé¨ {title}"
    if year:
        line += f" ({year})"
    line += f" ‚Äî {kind_ru}"

    if rating is not None:
        try:
            line += f" ‚Ä¢ ‚≠ê {float(rating):.1f}"
        except Exception:
            pass

    if overview:
        line += f"\n\n{overview[:700]}"
    return line

def _env(name: str, default: str = "") -> str:
    v = os.getenv(name)
    return v if v else default


def _pick_model() -> str:
    return _env("ASSISTANT_MODEL", "gpt-4.1-mini")

def _user_name(user: Optional[User]) -> str:
    for attr in ("first_name", "name", "username"):
        v = getattr(user, attr, None)
        if v:
            return str(v)
    return "–¥—Ä—É–≥"


def _user_tz(user: Optional[User]) -> ZoneInfo:
    tz_name = getattr(user, "tz", None) or "UTC"
    try:
        return ZoneInfo(str(tz_name))
    except Exception:
        return ZoneInfo("UTC")

def _assistant_plan(user: Optional[User]) -> str:
    if not user:
        return "free"

    now = datetime.now(timezone.utc)

    # –µ—Å–ª–∏ premium_until –µ—Å—Ç—å –∏ –æ–Ω –∏—Å—Ç—ë–∫ ‚Üí FREE
    pu = getattr(user, "premium_until", None)
    if pu is not None:
        if pu.tzinfo is None:
            pu = pu.replace(tzinfo=timezone.utc)
        if pu <= now:
            return "free"

    # –µ—Å–ª–∏ premium_until –Ω–µ—Ç –∏ is_premium=False ‚Üí FREE
    if pu is None and not bool(getattr(user, "is_premium", False)):
        return "free"

    # –ø—Ä–µ–º–∏—É–º –µ—Å—Ç—å ‚Üí —á–∏—Ç–∞–µ–º —Ç–∞—Ä–∏—Ñ
    plan = str(getattr(user, "premium_plan", "") or "").strip().lower()
    if plan in {"basic", "pro"}:
        return plan

    # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ –ø—Ä–µ–º–∏—É–º–∞
    return "basic"


def _now_str_user(user: Optional[User]) -> str:
    tz = _user_tz(user)
    return datetime.now(tz).strftime("%Y-%m-%d %H:%M")

def _is_media_query(text: str) -> bool:
    t = (text or "").lower()
    # –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ + —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è
    keys = (
        "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª", "–∫–∏–Ω–æ", "–º—É–ª—å—Ç", "–º—É–ª—å—Ç–∏–∫",
        "–ª–µ–Ω—Ç–∞", "–∫–∞–¥—Ä", "–ø–æ –∫–∞–¥—Ä—É", "–ø–æ —ç—Ç–æ–º—É –∫–∞–¥—Ä—É",
        "season", "episode", "movie", "tv", "series",
        "–∞–∫—Ç—ë—Ä", "–∞–∫—Ç–µ—Ä", "—Ä–µ–∂–∏—Å—Å", "–ø–µ—Ä—Å–æ–Ω–∞–∂",
        "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è", "—á—Ç–æ –∑–∞ —Ñ–∏–ª—å–º", "—á—Ç–æ –∑–∞ —Å–µ—Ä–∏–∞–ª", "—á—Ç–æ –∑–∞ –º—É–ª—å—Ç–∏–∫"
    )
    return any(k in t for k in keys)

def _is_noise(text: str) -> bool:
    s = (text or "").strip()
    if not s:
        return True

    if s in MENU_NOISE:
        return True

    letters = sum(ch.isalpha() for ch in s)
    if letters == 0:
        return True

    # —Å—É–ø–µ—Ä–∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –º—É—Å–æ—Ä (–Ω–æ 1-2 —Å–ª–æ–≤–∞ –∏–Ω–æ–≥–¥–∞ –≤–∞–∂–Ω—ã)
    if len(s) <= 3:
        return True

    tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë–Ü—ñ–á—ó–Ñ—î]+", s.lower())
    if tokens:
        most = max(tokens.count(x) for x in set(tokens))
        if most / max(1, len(tokens)) >= 0.6 and len(tokens) >= 4:
            return True

        if len(tokens) >= 4:
            uniq = set(tokens)
            if len(uniq) <= 2 and all(tokens.count(t) >= 2 for t in uniq):
                return True

    # –Ω–∏–∫/–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ —Å –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º (Pisya_Popa)
    if "_" in s and " " not in s and len(s) <= 20:
        return True

    return False


def meaning_score(s: str) -> float:
    s = (s or "").strip()
    if not s:
        return 0.0

    letters = sum(ch.isalpha() for ch in s)
    if letters == 0:
        return 0.0

    tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë–Ü—ñ–á—ó–Ñ—î]+", s.lower())
    w = len(tokens)

    score = 0.0

    if w >= 8:
        score += 0.45
    elif w >= 5:
        score += 0.30
    elif w >= 3:
        score += 0.15
    else:
        score -= 0.10

    ratio = letters / max(1, len(s))
    if ratio >= 0.55:
        score += 0.20
    elif ratio >= 0.35:
        score += 0.10
    else:
        score -= 0.15

    if tokens:
        most = max(tokens.count(x) for x in set(tokens))
        rep = most / max(1, len(tokens))
        if rep >= 0.6 and len(tokens) >= 4:
            score -= 0.35
        elif rep >= 0.4 and len(tokens) >= 5:
            score -= 0.15

    if any(x in s.lower() for x in ("bot_tg", "test", "asdf", "qwerty")):
        score -= 0.35

    return max(0.0, min(1.0, score))

def _as_user_ts(user: Optional[User], ts: Any) -> str:
    """
    created_at –∏–∑ sqlite –º–æ–∂–µ—Ç –±—ã—Ç—å naive.
    –°—á–∏—Ç–∞–µ–º naive –∫–∞–∫ UTC (—ç—Ç–æ —Å–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏),
    –ø–æ—Ç–æ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ tz —é–∑–µ—Ä–∞.
    """
    if ts is None:
        return "?"
    try:
        tz = _user_tz(user)
        if getattr(ts, "tzinfo", None) is None:
            ts = ts.replace(tzinfo=timezone.utc)
        return ts.astimezone(tz).strftime("%Y-%m-%d %H:%M")
    except Exception:
        try:
            return ts.strftime("%Y-%m-%d %H:%M")
        except Exception:
            return "?"


async def _fetch_recent_journal(
    session: Any,
    user: Optional[User],
    *,
    limit: int = 30,
    take: int = 5,
) -> list[tuple[str, str]]:
    if not session or not user:
        return []

    q = (
        select(JournalEntry.created_at, JournalEntry.text)
        .where(JournalEntry.user_id == user.id)
        .order_by(desc(JournalEntry.created_at))
        .limit(limit)
    )
    res = await session.execute(q)
    rows = res.all()

    out: list[tuple[str, str]] = []

    for created_at, text in rows:
        txt = (text or "").strip()
        if _is_noise(txt):
            continue

        created_str = _as_user_ts(user, created_at)
        out.append((created_str, txt[:700]))
        if len(out) >= take:
            break

    return out


async def build_context(session: Any, user: Optional[User], lang: str, plan: str) -> str:
    parts: list[str] = []
    parts.append(f"Time now: {_now_str_user(user)}")

    if user:
        parts.append(
            "User: "
            f"id={getattr(user,'id',None)}, "
            f"tg_id={getattr(user,'tg_id',None)}, "
            f"name={_user_name(user)}, "
            f"tz={getattr(user,'tz',None)}"
        )

        last_used = getattr(user, "assistant_last_used_at", None)
        if last_used:
            parts.append(f"Assistant last used at: {last_used}")

        profile = getattr(user, "assistant_profile_json", None)
        if profile:
            parts.append("Assistant profile (long-term):")
            parts.append(str(profile)[:2000])

    take = 0 if plan == "basic" else 5

    recent = await _fetch_recent_journal(session, user, limit=30, take=take)
    if recent:
        parts.append("Recent journal entries:")
        for ts, txt in recent:
            parts.append(f"- [{ts}] {txt}")

    return "\n".join(parts)

def _instructions(lang: str, plan: str) -> str:
    base_map = {
        "ru": (
            "–¢—ã ‚Äî –ª–∏—á–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram. –ü–∏—à–∏ –ø–æ-—Ä—É—Å—Å–∫–∏.\n"
            "–ù–µ –æ—Ü–µ–Ω–∏–≤–∞–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –Ω–µ –¥–µ–ª–∞–π –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏–∑.\n"
            "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –∑–∞–¥–∞–π 1 —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.\n"
        ),
        "uk": (
            "–¢–∏ ‚Äî –æ—Å–æ–±–∏—Å—Ç–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ —É Telegram. –ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n"
            "–ù–µ –æ—Ü—ñ–Ω—é–π –Ω–∞—Å—Ç—Ä—ñ–π —ñ –Ω–µ —Ä–æ–±–∏ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª—ñ–∑.\n"
            "–Ø–∫—â–æ –±—Ä–∞–∫—É—î –¥–∞–Ω–∏—Ö ‚Äî –ø–æ—Å—Ç–∞–≤ 1 —É—Ç–æ—á–Ω—é–≤–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è.\n"
        ),
        "en": (
            "You are a personal Telegram assistant. Reply in English.\n"
            "Do not psychoanalyze mood.\n"
            "If info is missing ‚Äî ask 1 clarifying question.\n"
        ),
    }

    base = base_map.get(lang, base_map["en"])

    style = (
        "–ü—Ä–∞–≤–∏–ª–∞ –æ—Ç–≤–µ—Ç–∞:\n"
        "- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω—ã '–°—É—Ç—å/–ü–ª–∞–Ω/–®–∞–≥–∏' –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç.\n"
        "- –ë–µ–∑ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏–∑–∞ –∏ –¥–∏–∞–≥–Ω–æ–∑–æ–≤.\n"
        "- –ö–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\n"
    )

    if plan == "basic":
        return base + style + (
            "–†–µ–∂–∏–º BASIC:\n"
            "- 2‚Äì6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n"
            "- –ë–µ–∑ –ø–ª–∞–Ω–æ–≤ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞.\n"
            "- –ñ—É—Ä–Ω–∞–ª –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –ø–∞–º—è—Ç—å.\n"
        )

    return base + style + (
        "–†–µ–∂–∏–º PRO:\n"
        "- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∂—É—Ä–Ω–∞–ª–∞ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n"
        "- –ú–æ–∂–Ω–æ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —á–µ–∫–ª–∏—Å—Ç—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.\n"
        "- –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –¥–æ 2 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.\n"
        "- –°—Ç–∏–ª—å: —É–º–Ω—ã–π –±–ª–∏–∑–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫.\n"
    )


async def run_assistant(
    user: Optional[User],
    text: str,
    lang: str,
    *,
    session: Any = None,
) -> str:
    if AsyncOpenAI is None:
        return "ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Å–µ—Ä–≤–µ—Ä –±–µ–∑ openai).\n–ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."

    api_key = _env("OPENAI_API_KEY")
    if not api_key:
        return {
            "uk": "‚ùå –ù–µ –∑–∞–¥–∞–Ω–æ OPENAI_API_KEY. –î–æ–¥–∞–π –∫–ª—é—á —É .env / –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞.",
            "en": "‚ùå OPENAI_API_KEY is missing. Add it to env/.env.",
            "ru": "‚ùå –ù–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY. –î–æ–±–∞–≤—å –∫–ª—é—á –≤ .env / –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.",
        }.get(lang, "‚ùå OPENAI_API_KEY missing.")

    client = AsyncOpenAI(api_key=api_key)
    model = _pick_model()
    plan = _assistant_plan(user)

    now = datetime.now(timezone.utc)

    # --- MEDIA state (DB + in-memory fallback) ---
    uid = _media_uid(user)
    st = _media_get(uid)  # in-memory session, survives even if session=None

    sticky_media_db = False
    if user:
        mode = getattr(user, "assistant_mode", None)
        until = getattr(user, "assistant_mode_until", None)
        if mode == "media" and until and until > now:
            sticky_media_db = True

    # IMPORTANT: if we have in-memory session => treat as media follow-up
    is_media = _is_media_query(text) or sticky_media_db or bool(st)

    if is_media:
        # 1) User picked an option number
        if st and _looks_like_choice(text):
            idx = int(text.strip()) - 1
            opts = st.get("items") or []
            if 0 <= idx < len(opts):
                return _format_one_media(opts[idx])

        # 1.5) "–ö–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è/–∫–∞–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ" ‚Äî —ç—Ç–æ –Ω–µ –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        if st and _is_asking_for_title(text):
            return build_media_context(st.get("items") or []) + "\n\n–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞."
        # 2) Build query (new query vs follow-up hint)# 2) Merge —É—Ç–æ—á–Ω–µ–Ω–∏–µ with previous query
        # 2) Build query (new query vs follow-up hint)
        raw = (text or "").strip()
        prev_q = ((st.get("query") if st else "") or "").strip()

        # –Ω–µ –¥–∞—ë–º "—è–¥–æ–≤–∏—Ç—ã–º" —Ñ—Ä–∞–∑–∞–º –ø–æ—Ä—Ç–∏—Ç—å –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
        if st and re.search(r"(?i)\b(–Ω–µ\s*—Ç–æ|–Ω–µ\s*–ø–æ–¥—Ö–æ–¥–∏—Ç|–Ω–∏—á–µ–≥–æ\s*–Ω–µ|—Ç–∞–∫–æ–≥–æ\s*—Ñ–∏–ª—å–º–∞|–Ω–µ\s*—Å—É—â–µ—Å—Ç–≤—É–µ—Ç)\b", raw):
            return MEDIA_NOT_FOUND_REPLY_RU

        # –∫–æ—Ä–æ—Ç–∫–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ (–≥–æ–¥/–∞–∫—Ç—ë—Ä/—Å—Ç—Ä–∞–Ω–∞/—è–∑—ã–∫/—Å–µ—Ä–∏—è/—ç–ø–∏–∑–æ–¥) ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –∫ –ø—Ä–æ—à–ª–æ–º—É –∑–∞–ø—Ä–æ—Å—É
        if st and prev_q and _looks_like_year_or_hint(raw) and len(raw) <= 60:
            query = _normalize_tmdb_query(f"{prev_q} {raw}")
        else:
            query = _normalize_tmdb_query(raw)


        # 3) Too generic ‚Üí ask 1 detail
        if len(query) < 6 and ("—Ñ–∏–ª—å–º" in query.lower() or "—á—Ç–æ –∑–∞" in query.lower()):
            # keep media mode alive for follow-ups even without DB session
            if user is not None:
                user.assistant_mode = "media"
                user.assistant_mode_until = now + timedelta(minutes=10)
                if session:
                    await session.commit()
            return MEDIA_NOT_FOUND_REPLY_RU

        # 4) Best-effort TMDb search (ru first, fallback en, year filter, dedupe, sort)
        query = _normalize_tmdb_query(query)
        try:
            print(f"[media] prev_q={prev_q!r} raw={raw!r} -> query={query!r}")
        except Exception:
            pass

        try:
            items = []

            # üîπ First try direct search by model/caption query
            items = await _tmdb_best_effort(query, limit=5)

            # üîπ If nothing found ‚Äî use parsed hints
            hints = _parse_media_hints(query)
            if hints.get("keywords"):
                items = await _tmdb_best_effort(hints["keywords"], limit=5)

            if not items and hints.get("cast"):
                from app.services.media_search import tmdb_search_person, tmdb_discover_with_people
                for actor in hints["cast"]:
                    pid = await tmdb_search_person(actor)
                    if pid:
                        items = await tmdb_discover_with_people(
                            pid,
                            year=hints.get("year"),
                            kind=hints.get("kind"),
                        )
                        if items:
                            break

        except Exception:
            items = []

        # keep sticky media mode (DB if possible)
        if user is not None:
            user.assistant_mode = "media"
            user.assistant_mode_until = now + timedelta(minutes=10)
            if session:
                await session.commit()

        if not items:
            # keep last query in memory so next hint still treated as media
            if uid:
                _media_set(uid, query, [])
            return MEDIA_NOT_FOUND_REPLY_RU

        _media_set(uid, query, items)
        return build_media_context(items) + "\n\n–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞."

    # ---- Normal assistant (non-media) ----
    ctx = await build_context(session, user, lang, plan)

    prev_id = getattr(user, "assistant_prev_response_id", None) if user else None
    if user:
        last_used = getattr(user, "assistant_last_used_at", None)
        if last_used and (datetime.now(timezone.utc) - last_used) > timedelta(hours=24):
            prev_id = None

    prompt = (
        f"Context:\n{ctx}\n\n"
        "User message:\n" + (text or "") + "\n"
    )

    resp = await client.responses.create(
        previous_response_id=prev_id,
        model=model,
        instructions=_instructions(lang, plan),
        input=prompt,
        max_output_tokens=(260 if plan == "basic" else 650),
    )

    if session:
        await log_llm_usage(
            session,
            user_id=getattr(user, "id", None) if user else None,
            feature="assistant",
            model=model,
            plan=plan,
            resp=resp,
            meta={"lang": lang},
        )

    out_text = (getattr(resp, "output_text", None) or "").strip()

    resp_id = getattr(resp, "id", None)
    if session and user and resp_id:
        changed = False
        if user.assistant_prev_response_id != str(resp_id):
            user.assistant_prev_response_id = str(resp_id)
            changed = True
        user.assistant_last_used_at = datetime.now(timezone.utc)
        changed = True

        if changed:
            await session.commit()

    if out_text:
        return out_text

    try:
        return str(getattr(resp, "output", "")).strip() or "‚ö†Ô∏è Empty response."
    except Exception:
        return "‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏."

async def run_assistant_vision(
    user: Optional[User],
    image_bytes: bytes,
    caption: str,
    lang: str,
    *,
    session: Any = None,
) -> str:
    if AsyncOpenAI is None:
        return "ü§ñ Vision –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Å–µ—Ä–≤–µ—Ä –±–µ–∑ openai)."

    api_key = _env("OPENAI_API_KEY")
    if not api_key:
        return {
            "uk": "‚ùå –ù–µ –∑–∞–¥–∞–Ω–æ OPENAI_API_KEY.",
            "en": "‚ùå OPENAI_API_KEY is missing.",
            "ru": "‚ùå –ù–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY.",
        }.get(lang, "‚ùå OPENAI_API_KEY missing.")

    plan = _assistant_plan(user)
    if plan != "pro":
        return {
            "ru": "–§–æ—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –≤ PRO.",
            "uk": "–§–æ—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–µ –ª–∏—à–µ –≤ PRO.",
            "en": "Photos are PRO-only.",
        }.get(lang, "PRO-only.")

    client = AsyncOpenAI(api_key=api_key)

    prompt_text = (caption or "").strip() or {
        "ru": "–û–ø—Ä–µ–¥–µ–ª–∏, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ. –ï—Å–ª–∏ —ç—Ç–æ –∫–∞–¥—Ä –∏–∑ —Ñ–∏–ª—å–º–∞/—Å–µ—Ä–∏–∞–ª–∞/–º—É–ª—å—Ç–∞ ‚Äî –ø–æ–ø—Ä–æ–±—É–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫.",
        "uk": "–í–∏–∑–Ω–∞—á, —â–æ –Ω–∞ —Ñ–æ—Ç–æ. –Ø–∫—â–æ —Ü–µ –∫–∞–¥—Ä –∑ —Ñ—ñ–ª—å–º—É/—Å–µ—Ä—ñ–∞–ª—É/–º—É–ª—å—Ç—Ñ—ñ–ª—å–º—É ‚Äî —Å–ø—Ä–æ–±—É–π –≤–∏–∑–Ω–∞—á–∏—Ç–∏ –¥–∂–µ—Ä–µ–ª–æ.",
        "en": "Identify what‚Äôs in the image. If it‚Äôs a movie/series/cartoon frame, try to identify the source.",
    }.get(lang, "Identify the image and, if it's a movie/series/cartoon frame, try to identify the source.")

    hard_keywords = (
        "—Ç–µ–∫—Å—Ç", "—á—Ç–æ –Ω–∞–ø–∏—Å–∞–Ω–æ", "–ø—Ä–æ—á–∏—Ç–∞–π", "—Å–∫—Ä–∏–Ω", "—Å–∫—Ä–∏–Ω—à–æ—Ç",
        "–æ—à–∏–±–∫–∞", "error", "traceback", "–ª–æ–≥", "qr", "–∫—å—é–∞—Ä",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–º–µ–Ω—é", "—á–µ–∫", "—Ä–µ—Ü–µ–ø—Ç", "—Å–æ—Å—Ç–∞–≤"
    )
    is_hard = any(k in prompt_text.lower() for k in hard_keywords)

    model_default = _env("ASSISTANT_VISION_MODEL", _pick_model())
    model_hard = _env("ASSISTANT_VISION_MODEL_HARD", model_default)
    model = model_hard if is_hard else model_default

    import base64
    b64 = base64.b64encode(image_bytes).decode("utf-8")
    data_url = f"data:image/jpeg;base64,{b64}"

    now = datetime.now(timezone.utc)

    instr = (
        ANTI_HALLUCINATION_PREFIX
        + _instructions(lang, plan)
        + "\n"
        + (
            "–¢—ã –≤–∏–¥–∏—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n"
            "–ï—Å–ª–∏ —ç—Ç–æ –∫–∞–¥—Ä –∏–∑ —Ñ–∏–ª—å–º–∞/—Å–µ—Ä–∏–∞–ª–∞/–º—É–ª—å—Ç–∞/–∞–Ω–∏–º–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫.\n"
            "–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏.\n\n"
            "–í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫—É:\n"
            "SEARCH_QUERY: <–∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ (–Ω–∞–∑–≤–∞–Ω–∏–µ/–ø–µ—Ä—Å–æ–Ω–∞–∂/–≥–æ–¥/–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)>\n"
            "–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å ‚Äî –Ω–∞–ø–∏—à–∏:\n"
            "SEARCH_QUERY:\n"
        )
    )

    try:
        resp = await client.responses.create(
            model=model,
            instructions=instr,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": prompt_text},
                        {"type": "input_image", "image_url": data_url},
                    ],
                }
            ],
            max_output_tokens=450,
        )
    except Exception as e:
        return {
            "ru": f"‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ ({type(e).__name__}). –ü–æ–ø—Ä–æ–±—É–π –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–ª–∏ —Å–∂–∞—Ç—å —Å–∫—Ä–∏–Ω.",
            "uk": f"‚ö†Ô∏è –ù–µ –∑–º—ñ–≥ –æ–±—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ ({type(e).__name__}). –°–ø—Ä–æ–±—É–π –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ –º–µ–Ω—à–µ —Ñ–æ—Ç–æ –∞–±–æ —Å—Ç–∏—Å–Ω—É—Ç–∏ —Å–∫—Ä—ñ–Ω.",
            "en": f"‚ö†Ô∏è I couldn‚Äôt process the photo ({type(e).__name__}). Try sending a smaller image or compress the screenshot.",
        }.get(lang, f"‚ö†Ô∏è Vision error: {type(e).__name__}")

    if session:
        await log_llm_usage(
            session,
            user_id=getattr(user, "id", None) if user else None,
            feature="vision",
            model=model,
            plan=plan,
            resp=resp,
            meta={"lang": lang},
        )

    out_text = (getattr(resp, "output_text", None) or "").strip()
    out_text = str(out_text)

    # trace.moe (anime) ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —è–≤–Ω–æ —Å–∫–∞–∑–∞–ª–∞ "–∞–Ω–∏–º–µ"
    if any(k in out_text.lower() for k in ("–∞–Ω–∏–º–µ", "anime")):
        try:
            result = await trace_moe_identify(image_bytes)
        except Exception:
            result = None

        if result:
            sim = float(result.get("similarity", 0) or 0)
            if sim >= 0.9:
                return (
                    "üé¨ –≠—Ç–æ –∫–∞–¥—Ä –∏–∑ –∞–Ω–∏–º–µ.\n\n"
                    f"–ù–∞–∑–≤–∞–Ω–∏–µ: {result.get('title')}\n"
                    f"–°–µ—Ä–∏—è: {result.get('episode')}\n"
                    f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {sim:.1%}"
                )
    # –∏–Ω–∞—á–µ ‚Äî –Ω–µ –ª–æ–º–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫, –ø—Ä–æ—Å—Ç–æ –∏–¥—ë–º –¥–∞–ª—å—à–µ (TMDb)
    # Vision ‚Üí TMDb candidates
    caption_str = (caption or "").strip()
    search_q = _normalize_tmdb_query(_extract_search_query_from_text(out_text))
    tmdb_q = search_q or _normalize_tmdb_query(caption_str)

    if tmdb_q:
        try:
            items = []

            # üîπ First try direct search by model/caption query
            items = await _tmdb_best_effort(tmdb_q, limit=5)

            # üîπ If nothing found ‚Äî use parsed hints
            hints = _parse_media_hints(tmdb_q)
            if hints.get("keywords"):
                items = await _tmdb_best_effort(hints["keywords"], limit=5)

            if not items and hints.get("cast"):
                from app.services.media_search import tmdb_search_person, tmdb_discover_with_people
                for actor in hints["cast"]:
                    pid = await tmdb_search_person(actor)
                    if pid:
                        items = await tmdb_discover_with_people(
                            pid,
                            year=hints.get("year"),
                            kind=hints.get("kind"),
                        )
                        if items:
                            break

        except Exception:
            items = []

        if items:
            if user is not None:
                user.assistant_mode = "media"
                user.assistant_mode_until = now + timedelta(minutes=10)
                if session:
                    await session.commit()

            uid = _media_uid(user)
            if uid:
                _media_set(uid, tmdb_q, items)

            return build_media_context(items) + "–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞."

        return MEDIA_NOT_FOUND_REPLY_RU
    
    # --- Failsafe: Vision must always return text ---
    final_text = (out_text or "").strip()

    if not final_text:
        final_text = (
            "–Ø –Ω–µ —Å–º–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. "
            "–ü–æ–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç—å —Å—Ü–µ–Ω—É —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª—å "
            "(–∞–∫—Ç—ë—Ä, –≥–æ–¥, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç)."
        )

    return final_text