# app/services/assistant.py
from __future__ import annotations

import os
import json
import re
from datetime import datetime, timezone, timedelta, time as dtime
from typing import Optional, Any

from zoneinfo import ZoneInfo
from sqlalchemy import select, desc
try:
    from openai import AsyncOpenAI
except ModuleNotFoundError:
    AsyncOpenAI = None  # type: ignore

from app.models.user import User
from app.models.journal import JournalEntry
from app.services.llm_usage import log_llm_usage
from app.services.media_id import trace_moe_identify
from app.services.media_search import tmdb_search_multi, build_media_context


MENU_NOISE = {
    "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üßæ –°–µ–≥–æ–¥–Ω—è", "üìì –ñ—É—Ä–Ω–∞–ª", "üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é",
    "üíé –ü—Ä–µ–º–∏—É–º", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", "üßò –ú–µ–¥–∏–∞",
}

ANTI_HALLUCINATION_PREFIX = (
    "–í–ê–ñ–ù–û:\n"
    "- –ï—Å–ª–∏ —Ç—ã –ù–ï –£–í–ï–†–ï–ù(–∞) ‚Äî –ø—Ä—è–º–æ —Å–∫–∞–∂–∏: '–Ω–µ —É–≤–µ—Ä–µ–Ω(–∞)'.\n"
    "- –ù–ï —É–≥–∞–¥—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–æ–≤/–º—É–ª—å—Ç—Ñ–∏–ª—å–º–æ–≤/–ª—é–¥–µ–π/–º–µ—Å—Ç.\n"
    "- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –≤–∏–¥–Ω–æ.\n"
    "- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –∑–∞–¥–∞–π 1 —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.\n\n"
)

MEDIA_NOT_FOUND_REPLY_RU = (
    "–ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –±–∞–∑–µ. –î–∞–π 1 –¥–µ—Ç–∞–ª—å, –∏ —è –ø–æ–ø—Ä–æ–±—É—é –µ—â—ë —Ä–∞–∑: "
    "–≥–æ–¥ / –∞–∫—Ç—ë—Ä / —Å—Ç—Ä–∞–Ω–∞ / —è–∑—ã–∫ / —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Å—Ü–µ–Ω–µ (1‚Äì2 —Ñ–∞–∫—Ç–∞)."
)


def _env(name: str, default: str = "") -> str:
    v = os.getenv(name)
    return v if v else default


def _pick_model() -> str:
    return _env("ASSISTANT_MODEL", "gpt-4.1-mini")


def _user_name(user: Optional[User]) -> str:
    for attr in ("first_name", "name", "username"):
        v = getattr(user, attr, None)
        if v:
            return str(v)
    return "–¥—Ä—É–≥"


def _user_tz(user: Optional[User]) -> ZoneInfo:
    tz_name = getattr(user, "tz", None) or "UTC"
    try:
        return ZoneInfo(str(tz_name))
    except Exception:
        return ZoneInfo("UTC")
    
def _assistant_plan(user: Optional[User]) -> str:
    if not user:
        return "free"

    now = datetime.now(timezone.utc)

    # –µ—Å–ª–∏ premium_until –µ—Å—Ç—å –∏ –æ–Ω –∏—Å—Ç—ë–∫ ‚Üí FREE
    pu = getattr(user, "premium_until", None)
    if pu is not None:
        if pu.tzinfo is None:
            pu = pu.replace(tzinfo=timezone.utc)
        if pu <= now:
            return "free"

    # –µ—Å–ª–∏ premium_until –Ω–µ—Ç –∏ is_premium=False ‚Üí FREE
    if pu is None and not bool(getattr(user, "is_premium", False)):
        return "free"

    # –ø—Ä–µ–º–∏—É–º –µ—Å—Ç—å ‚Üí —á–∏—Ç–∞–µ–º —Ç–∞—Ä–∏—Ñ
    plan = str(getattr(user, "premium_plan", "") or "").strip().lower()
    if plan in {"basic", "pro"}:
        return plan

    # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ –ø—Ä–µ–º–∏—É–º–∞
    return "basic"


def _now_str_user(user: Optional[User]) -> str:
    tz = _user_tz(user)
    return datetime.now(tz).strftime("%Y-%m-%d %H:%M")


def _is_media_query(text: str) -> bool:
    t = (text or "").lower()
    # –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ + —Ç–∏–ø–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è
    keys = (
        "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª", "–∫–∏–Ω–æ", "–º—É–ª—å—Ç", "–º—É–ª—å—Ç–∏–∫",
        "–ª–µ–Ω—Ç–∞", "–∫–∞–¥—Ä", "–ø–æ –∫–∞–¥—Ä—É", "–ø–æ —ç—Ç–æ–º—É –∫–∞–¥—Ä—É",
        "season", "episode", "movie", "tv", "series",
        "–∞–∫—Ç—ë—Ä", "–∞–∫—Ç–µ—Ä", "—Ä–µ–∂–∏—Å—Å", "–ø–µ—Ä—Å–æ–Ω–∞–∂",
        "–∫–∞–∫ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è", "—á—Ç–æ –∑–∞ —Ñ–∏–ª—å–º", "—á—Ç–æ –∑–∞ —Å–µ—Ä–∏–∞–ª", "—á—Ç–æ –∑–∞ –º—É–ª—å—Ç–∏–∫"
    )
    return any(k in t for k in keys)


def _is_noise(text: str) -> bool:
    s = (text or "").strip()
    if not s:
        return True

    if s in MENU_NOISE:
        return True

    letters = sum(ch.isalpha() for ch in s)
    if letters == 0:
        return True

    # —Å—É–ø–µ—Ä–∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –º—É—Å–æ—Ä (–Ω–æ 1-2 —Å–ª–æ–≤–∞ –∏–Ω–æ–≥–¥–∞ –≤–∞–∂–Ω—ã)
    if len(s) <= 3:
        return True

    tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë–Ü—ñ–á—ó–Ñ—î]+", s.lower())
    if tokens:
        most = max(tokens.count(x) for x in set(tokens))
        if most / max(1, len(tokens)) >= 0.6 and len(tokens) >= 4:
            return True

        if len(tokens) >= 4:
            uniq = set(tokens)
            if len(uniq) <= 2 and all(tokens.count(t) >= 2 for t in uniq):
                return True

    # –Ω–∏–∫/–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ —Å –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º (Pisya_Popa)
    if "_" in s and " " not in s and len(s) <= 20:
        return True

    return False


def meaning_score(s: str) -> float:
    s = (s or "").strip()
    if not s:
        return 0.0

    letters = sum(ch.isalpha() for ch in s)
    if letters == 0:
        return 0.0

    tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë–Ü—ñ–á—ó–Ñ—î]+", s.lower())
    w = len(tokens)

    score = 0.0

    if w >= 8:
        score += 0.45
    elif w >= 5:
        score += 0.30
    elif w >= 3:
        score += 0.15
    else:
        score -= 0.10

    ratio = letters / max(1, len(s))
    if ratio >= 0.55:
        score += 0.20
    elif ratio >= 0.35:
        score += 0.10
    else:
        score -= 0.15

    if tokens:
        most = max(tokens.count(x) for x in set(tokens))
        rep = most / max(1, len(tokens))
        if rep >= 0.6 and len(tokens) >= 4:
            score -= 0.35
        elif rep >= 0.4 and len(tokens) >= 5:
            score -= 0.15

    if any(x in s.lower() for x in ("bot_tg", "test", "asdf", "qwerty")):
        score -= 0.35

    return max(0.0, min(1.0, score))


def _as_user_ts(user: Optional[User], ts: Any) -> str:
    """
    created_at –∏–∑ sqlite –º–æ–∂–µ—Ç –±—ã—Ç—å naive.
    –°—á–∏—Ç–∞–µ–º naive –∫–∞–∫ UTC (—ç—Ç–æ —Å–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏),
    –ø–æ—Ç–æ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ tz —é–∑–µ—Ä–∞.
    """
    if ts is None:
        return "?"
    try:
        tz = _user_tz(user)
        if getattr(ts, "tzinfo", None) is None:
            ts = ts.replace(tzinfo=timezone.utc)
        return ts.astimezone(tz).strftime("%Y-%m-%d %H:%M")
    except Exception:
        try:
            return ts.strftime("%Y-%m-%d %H:%M")
        except Exception:
            return "?"


async def _fetch_recent_journal(
    session: Any,
    user: Optional[User],
    *,
    limit: int = 30,
    take: int = 5,
) -> list[tuple[str, str]]:
    if not session or not user:
        return []

    q = (
        select(JournalEntry.created_at, JournalEntry.text)
        .where(JournalEntry.user_id == user.id)
        .order_by(desc(JournalEntry.created_at))
        .limit(limit)
    )
    res = await session.execute(q)
    rows = res.all()

    out: list[tuple[str, str]] = []

    for created_at, text in rows:
        txt = (text or "").strip()
        if _is_noise(txt):
            continue

        created_str = _as_user_ts(user, created_at)
        out.append((created_str, txt[:700]))
        if len(out) >= take:
            break

    return out


async def build_context(session: Any, user: Optional[User], lang: str, plan: str) -> str:
    parts: list[str] = []
    parts.append(f"Time now: {_now_str_user(user)}")

    if user:
        parts.append(
            "User: "
            f"id={getattr(user,'id',None)}, "
            f"tg_id={getattr(user,'tg_id',None)}, "
            f"name={_user_name(user)}, "
            f"tz={getattr(user,'tz',None)}"
        )

        last_used = getattr(user, "assistant_last_used_at", None)
        if last_used:
            parts.append(f"Assistant last used at: {last_used}")

        profile = getattr(user, "assistant_profile_json", None)
        if profile:
            parts.append("Assistant profile (long-term):")
            parts.append(str(profile)[:2000])

    take = 0 if plan == "basic" else 5

    recent = await _fetch_recent_journal(session, user, limit=30, take=take)
    if recent:
        parts.append("Recent journal entries:")
        for ts, txt in recent:
            parts.append(f"- [{ts}] {txt}")

    return "\n".join(parts)



def _instructions(lang: str, plan: str) -> str:
    base_map = {
        "ru": (
            "–¢—ã ‚Äî –ª–∏—á–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram. –ü–∏—à–∏ –ø–æ-—Ä—É—Å—Å–∫–∏.\n"
            "–ù–µ –æ—Ü–µ–Ω–∏–≤–∞–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –Ω–µ –¥–µ–ª–∞–π –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏–∑.\n"
            "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –∑–∞–¥–∞–π 1 —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.\n"
        ),
        "uk": (
            "–¢–∏ ‚Äî –æ—Å–æ–±–∏—Å—Ç–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ —É Telegram. –ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é.\n"
            "–ù–µ –æ—Ü—ñ–Ω—é–π –Ω–∞—Å—Ç—Ä—ñ–π —ñ –Ω–µ —Ä–æ–±–∏ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª—ñ–∑.\n"
            "–Ø–∫—â–æ –±—Ä–∞–∫—É—î –¥–∞–Ω–∏—Ö ‚Äî –ø–æ—Å—Ç–∞–≤ 1 —É—Ç–æ—á–Ω—é–≤–∞–ª—å–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è.\n"
        ),
        "en": (
            "You are a personal Telegram assistant. Reply in English.\n"
            "Do not psychoanalyze mood.\n"
            "If info is missing ‚Äî ask 1 clarifying question.\n"
        ),
    }

    base = base_map.get(lang, base_map["en"])

    style = (
        "–ü—Ä–∞–≤–∏–ª–∞ –æ—Ç–≤–µ—Ç–∞:\n"
        "- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω—ã '–°—É—Ç—å/–ü–ª–∞–Ω/–®–∞–≥–∏' –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç.\n"
        "- –ë–µ–∑ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏–∑–∞ –∏ –¥–∏–∞–≥–Ω–æ–∑–æ–≤.\n"
        "- –ö–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\n"
    )

    if plan == "basic":
        return base + style + (
            "–†–µ–∂–∏–º BASIC:\n"
            "- 2‚Äì6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n"
            "- –ë–µ–∑ –ø–ª–∞–Ω–æ–≤ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –±–µ–∑ –∑–∞–ø—Ä–æ—Å–∞.\n"
            "- –ñ—É—Ä–Ω–∞–ª –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –ø–∞–º—è—Ç—å.\n"
        )

    return base + style + (
        "–†–µ–∂–∏–º PRO:\n"
        "- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∂—É—Ä–Ω–∞–ª–∞ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n"
        "- –ú–æ–∂–Ω–æ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —á–µ–∫–ª–∏—Å—Ç—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.\n"
        "- –ú–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –¥–æ 2 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.\n"
        "- –°—Ç–∏–ª—å: —É–º–Ω—ã–π –±–ª–∏–∑–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫.\n"
    )


async def run_assistant(
    user: Optional[User],
    text: str,
    lang: str,
    *,
    session: Any = None,
) -> str:
    if AsyncOpenAI is None:
        return "ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Å–µ—Ä–≤–µ—Ä –±–µ–∑ openai).\n–ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."

    api_key = _env("OPENAI_API_KEY")
    if not api_key:
        return {
            "uk": "‚ùå –ù–µ –∑–∞–¥–∞–Ω–æ OPENAI_API_KEY. –î–æ–¥–∞–π –∫–ª—é—á —É .env / –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞.",
            "en": "‚ùå OPENAI_API_KEY is missing. Add it to env/.env.",
            "ru": "‚ùå –ù–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY. –î–æ–±–∞–≤—å –∫–ª—é—á –≤ .env / –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.",
        }.get(lang, "‚ùå OPENAI_API_KEY missing.")

    client = AsyncOpenAI(api_key=api_key)
    model = _pick_model()

    plan = _assistant_plan(user)

    # --- MEDIA RAG (films/series): retrieve before generation ---
    media_ctx = ""
    items = []  # tmdb candidates
    now = datetime.now(timezone.utc)
    sticky_media = False
    if user:
        mode = getattr(user, "assistant_mode", None)
        until = getattr(user, "assistant_mode_until", None)
        if mode == "media" and until and until > now:
            sticky_media = True

    is_media = _is_media_query(text) or sticky_media
    if is_media:
        try:
            items = await tmdb_search_multi(text, lang="ru-RU", limit=5)
            media_ctx = build_media_context(items)
            # MEDIA_HARD_FALLBACK: –µ—Å–ª–∏ –Ω–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ‚Äî –Ω–µ —É—Ö–æ–¥–∏–º –≤ –±–æ–ª—Ç–æ–≤–Ω—é, –ø—Ä–æ—Å–∏–º 1 –¥–µ—Ç–∞–ª—å
            if media_ctx.startswith("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ") or media_ctx.startswith("TMDb error"):
                # –ø—Ä–æ–¥–ª–µ–≤–∞–µ–º sticky-—Ä–µ–∂–∏–º, —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—á–∏—Ç–∞–ª–æ—Å—å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º
                if user is not None:
                    user.assistant_mode = "media"
                    user.assistant_mode_until = now + timedelta(minutes=10)
                    if session:
                        await session.commit()
                return MEDIA_NOT_FOUND_REPLY_RU
        except Exception:
            media_ctx = "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."
        # ‚úÖ HARD MEDIA GUARD: no hallucination for media id
        if is_media:
            if (not items) or (len(items) == 1 and items[0].get("_error")):
                return (
                    "–ù–µ —É–≤–µ—Ä–µ–Ω(–∞), —á—Ç–æ –º–æ–≥—É –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–∏–ª—å–º/—Å–µ—Ä–∏–∞–ª –ø–æ —ç—Ç–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é.\n"
                    "–°–∫–∞–∂–∏ 1 –¥–µ—Ç–∞–ª—å: –≥–æ–¥/–∞–∫—Ç—ë—Ä/—è–∑—ã–∫/—Å—Ç—Ä–∞–Ω–∞ –∏–ª–∏ —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –∫–∞–¥—Ä–µ (2‚Äì3 —Ñ–∞–∫—Ç–∞)."
                )
            return build_media_context(items) + "\n\n–ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –±–ª–∏–∂–µ? (–æ—Ç–≤–µ—Ç—å –Ω–æ–º–µ—Ä–æ–º)"


    ctx = await build_context(session, user, lang, plan)

    prev_id = getattr(user, "assistant_prev_response_id", None) if user else None

    # –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è > 24 —á–∞—Å–æ–≤ ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ç–∫—É
    if user:
        last_used = getattr(user, "assistant_last_used_at", None)
        if last_used and (datetime.now(timezone.utc) - last_used) > timedelta(hours=24):
            prev_id = None

    prompt = (
        f"Context:\n{ctx}\n\n"
        + (f"Media DB search context (TMDb):\n{media_ctx}\n\n" if media_ctx else "")
        + "User message:\n" + text + "\n"
    )

    media_rules = ""
    if is_media:
        media_rules = """
–í–ê–ñ–ù–û (MEDIA MODE):
- –¢—ã –≤ —Ä–µ–∂–∏–º–µ –ü–û–ò–°–ö–ê —Ñ–∏–ª—å–º–∞/—Å–µ—Ä–∏–∞–ª–∞. –ù–µ –æ–±—Å—É–∂–¥–∞–π —Å—é–∂–µ—Ç, —ç–º–æ—Ü–∏–∏ –∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏.
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –∫–∞–∫ –ø–æ–∏—Å–∫–æ–≤–∏–∫: –ø–æ–∫–∞–∂–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ TMDb –∏–ª–∏ —Å–∫–∞–∂–∏ '–Ω–µ —É–≤–µ—Ä–µ–Ω(–∞)'.
- –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–µ—Ç/–¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ ‚Äî –ø–æ–ø—Ä–æ—Å–∏ 1 —É—Ç–æ—á–Ω–µ–Ω–∏–µ (–≥–æ–¥/–∞–∫—Ç—ë—Ä/—Å—Ü–µ–Ω–∞/—è–∑—ã–∫/—Å—Ç—Ä–∞–Ω–∞).
- –ù–ï —É–≥–∞–¥—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã.
"""
    # –¥–ª—è media-–∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç–∫–ª—é—á–∞–µ–º previous_response_id, —á—Ç–æ–±—ã –Ω–µ —Ç—è–Ω—É—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ç–∫—É –∏ –Ω–µ –≥–∞–ª—é–Ω–∏–ª–æ
    prev_for_call = prev_id  # keep thread even for media (sticky follow-ups)

    resp = await client.responses.create(
        previous_response_id=prev_for_call,
        model=model,
        instructions=_instructions(lang, plan) + media_rules,
        input=prompt,
        max_output_tokens=(260 if plan == "basic" else 650),
    )

    if session:
        await log_llm_usage(
            session,
            user_id=getattr(user, "id", None) if user else None,
            feature="assistant",
            model=model,
            plan=plan,
            resp=resp,
            meta={"lang": lang},
        )

    out = getattr(resp, "output_text", None)
    out_text = (out or "").strip()

    resp_id = getattr(resp, "id", None)
    if session and user and resp_id:
        changed = False
        if user.assistant_prev_response_id != str(resp_id):
            user.assistant_prev_response_id = str(resp_id)
            changed = True
        user.assistant_last_used_at = datetime.now(timezone.utc)
        # sticky media-mode: –ø—Ä–æ–¥–ª–µ–≤–∞–µ–º –Ω–∞ 2 –º–∏–Ω—É—Ç—ã, —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–∏–π –º–µ—Å—Å–µ–¥–∂ —Å—á–∏—Ç–∞–ª—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º
        if is_media:
            user.assistant_mode = "media"
            user.assistant_mode_until = now + timedelta(minutes=10)
            changed = True

        changed = True

        if changed:
            await session.commit()

    if out_text:
        return out_text

    # fallback
    try:
        return str(getattr(resp, "output", "")).strip() or "‚ö†Ô∏è Empty response."
    except Exception:
        return "‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏."
    

async def run_assistant_vision(
    user: Optional[User],
    image_bytes: bytes,
    caption: str,
    lang: str,
    *,
    session: Any = None,
) -> str:
    if AsyncOpenAI is None:
        return "ü§ñ Vision –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Å–µ—Ä–≤–µ—Ä –±–µ–∑ openai)."

    api_key = _env("OPENAI_API_KEY")
    if not api_key:
        return {
            "uk": "‚ùå –ù–µ –∑–∞–¥–∞–Ω–æ OPENAI_API_KEY.",
            "en": "‚ùå OPENAI_API_KEY is missing.",
            "ru": "‚ùå –ù–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY.",
        }.get(lang, "‚ùå OPENAI_API_KEY missing.")

    plan = _assistant_plan(user)
    if plan != "pro":
        return {"ru": "–§–æ—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –≤ PRO.", "uk": "–§–æ—Ç–æ –¥–æ—Å—Ç—É–ø–Ω–µ –ª–∏—à–µ –≤ PRO.", "en": "Photos are PRO-only."}.get(lang, "PRO-only.")

    client = AsyncOpenAI(api_key=api_key)

    prompt_text = (caption or "").strip()
    if not prompt_text:
        prompt_text = {
            "ru": "–û–ø—Ä–µ–¥–µ–ª–∏, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ, –∏ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø–æ–ª–µ–∑–Ω—ã–π –≤—ã–≤–æ–¥.",
            "uk": "–í–∏–∑–Ω–∞—á, —â–æ –Ω–∞ —Ñ–æ—Ç–æ, —ñ –¥–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ—Ä–∏—Å–Ω–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫.",
            "en": "Identify what‚Äôs in the photo and give a short helpful takeaway.",
        }.get(lang, "Identify the image and give a short helpful takeaway.")

    # ‚úÖ –∞–≤—Ç–æ-—É—Å–∏–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è ‚Äú—Å–ª–æ–∂–Ω—ã—Ö‚Äù –∑–∞–¥–∞—á (—Å–∫—Ä–∏–Ω—ã/—Ç–µ–∫—Å—Ç/–æ—à–∏–±–∫–∏)
    hard_keywords = (
        "—Ç–µ–∫—Å—Ç", "—á—Ç–æ –Ω–∞–ø–∏—Å–∞–Ω–æ", "–ø—Ä–æ—á–∏—Ç–∞–π", "—Å–∫—Ä–∏–Ω", "—Å–∫—Ä–∏–Ω—à–æ—Ç",
        "–æ—à–∏–±–∫–∞", "error", "traceback", "–ª–æ–≥", "qr", "–∫—å—é–∞—Ä",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–º–µ–Ω—é", "—á–µ–∫", "—Ä–µ—Ü–µ–ø—Ç", "—Å–æ—Å—Ç–∞–≤"
    )
    is_hard = any(k in prompt_text.lower() for k in hard_keywords)

    model_default = _env("ASSISTANT_VISION_MODEL", _pick_model())
    model_hard = _env("ASSISTANT_VISION_MODEL_HARD", model_default)
    model = model_hard if is_hard else model_default

    # ‚úÖ data-url
    import base64
    b64 = base64.b64encode(image_bytes).decode("utf-8")
    data_url = f"data:image/jpeg;base64,{b64}"  # –¥–ª—è F.photo –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ jpeg


    # --- sticky MEDIA MODE after vision (so next text is treated as —É—Ç–æ—á–Ω–µ–Ω–∏–µ) ---
    now = datetime.now(timezone.utc)
    is_media = _is_media_query(prompt_text)
    if session and user and is_media:
        try:
            user.assistant_mode = "media"
            user.assistant_mode_until = now + timedelta(minutes=10)
            await session.commit()
        except Exception:
            pass

    instr = ANTI_HALLUCINATION_PREFIX + _instructions(lang, plan) + "\n" + (
        "–¢—ã –≤–∏–¥–∏—à—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –û—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É. "
        "–ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º. "
        "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏."
    )

    try:
        resp = await client.responses.create(
            model=model,
            instructions=instr,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": prompt_text},
                        {"type": "input_image", "image_url": data_url},
                    ],
                }
            ],
            max_output_tokens=450,
        )
    except Exception as e:
        # ‚úÖ –ø–æ–Ω—è—Ç–Ω—ã–π —Ñ–æ–ª–±—ç–∫ –¥–ª—è —é–∑–µ—Ä–∞ –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è
        return {
            "ru": f"‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ ({type(e).__name__}). –ü–æ–ø—Ä–æ–±—É–π –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–ª–∏ —Å–∂–∞—Ç—å —Å–∫—Ä–∏–Ω.",
            "uk": f"‚ö†Ô∏è –ù–µ –∑–º—ñ–≥ –æ–±—Ä–æ–±–∏—Ç–∏ —Ñ–æ—Ç–æ ({type(e).__name__}). –°–ø—Ä–æ–±—É–π –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ –º–µ–Ω—à–µ —Ñ–æ—Ç–æ –∞–±–æ —Å—Ç–∏—Å–Ω—É—Ç–∏ —Å–∫—Ä—ñ–Ω.",
            "en": f"‚ö†Ô∏è I couldn‚Äôt process the photo ({type(e).__name__}). Try sending a smaller image or compressing the screenshot.",
        }.get(lang, f"‚ö†Ô∏è Vision error: {type(e).__name__}")
    
    if session:
        await log_llm_usage(
            session,
            user_id=getattr(user, "id", None) if user else None,
            feature="vision",
            model=model,
            plan=plan,
            resp=resp,
            meta={"lang": lang},
        )

    out_text = (getattr(resp, "output_text", None) or "").strip()
    # üéûÔ∏è Anime / cartoon frame detection via trace.moe
    if any(k in out_text.lower() for k in ("–∞–Ω–∏–º–µ", "anime", "–º—É–ª—å—Ç", "cartoon")):
        result = await trace_moe_identify(image_bytes)
        if result and result["similarity"] >= 0.9:
            return (
                f"üé¨ –≠—Ç–æ –∫–∞–¥—Ä –∏–∑ –∞–Ω–∏–º–µ.\n\n"
                f"–ù–∞–∑–≤–∞–Ω–∏–µ: {result['title']}\n"
                f"–°–µ—Ä–∏—è: {result['episode']}\n"
                f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {result['similarity']:.1%}"
            )
        elif result:
            return (
                "üé¨ –ü–æ—Ö–æ–∂–µ –Ω–∞ –∞–Ω–∏–º–µ, –Ω–æ –Ω–µ —É–≤–µ—Ä–µ–Ω.\n\n"
                f"–í–æ–∑–º–æ–∂–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: {result['title']}\n"
                f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {result['similarity']:.1%}"
            )
    if out_text:
        return out_text

    try:
        return str(getattr(resp, "output", "")).strip() or "‚ö†Ô∏è Empty response."
    except Exception:
        return "‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç vision."
